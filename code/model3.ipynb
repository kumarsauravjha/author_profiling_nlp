{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted my_conda_env (Python 3.12.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49fb527-2071-43fc-9d5d-fec423f7404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbfa28d-c236-4a18-8024-741f28cde872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"archive/blogtext.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ed889-32fd-4eba-96e2-cedd4f8e4bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "17    80859\n",
       "24    80071\n",
       "23    72889\n",
       "16    72708\n",
       "25    67051\n",
       "26    55312\n",
       "27    46124\n",
       "15    41767\n",
       "14    27400\n",
       "34    21347\n",
       "33    17584\n",
       "35    17462\n",
       "36    14229\n",
       "13    13133\n",
       "37     9317\n",
       "38     7545\n",
       "39     5556\n",
       "40     5016\n",
       "45     4482\n",
       "43     4230\n",
       "41     3738\n",
       "48     3572\n",
       "42     2908\n",
       "46     2733\n",
       "47     2207\n",
       "44     2044\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb776ff2-4871-4dbf-8228-ae9c0dc0f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the text data\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove non-alphanumeric characters and extra spaces\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6d7213-a6d2-4afa-9d68-fd9d0b38324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "# Encode the gender column\n",
    "label_encoder = LabelEncoder()\n",
    "df['gender_encoded'] = label_encoder.fit_transform(df['gender'])  # Male: 0, Female: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e8a1ee-b2fe-4ac3-8a0c-f633884c267f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occupation_grouped\n",
      "Public-Services-Misc         420683\n",
      "Creative-Social-Education    122837\n",
      "STEM                          91538\n",
      "Business-Finance-Law          46226\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the mapping\n",
    "occupation_mapping = {\n",
    "    # STEM\n",
    "    'Technology': 'STEM', 'Engineering': 'STEM', 'Internet': 'STEM', 'Science': 'STEM',\n",
    "    'Biotech': 'STEM', 'Telecommunications': 'STEM', 'Manufacturing': 'STEM', \n",
    "    'Chemicals': 'STEM', 'Architecture': 'STEM', 'Environment': 'STEM', 'Maritime': 'STEM',\n",
    "    \n",
    "    # Business, Finance, and Law\n",
    "    'BusinessServices': 'Business-Finance-Law', 'Banking': 'Business-Finance-Law',\n",
    "    'Accounting': 'Business-Finance-Law', 'InvestmentBanking': 'Business-Finance-Law',\n",
    "    'RealEstate': 'Business-Finance-Law', 'Marketing': 'Business-Finance-Law', \n",
    "    'Advertising': 'Business-Finance-Law', 'Consulting': 'Business-Finance-Law',\n",
    "    'Law': 'Business-Finance-Law', 'HumanResources': 'Business-Finance-Law',\n",
    "    'Transportation': 'Business-Finance-Law',\n",
    "    \n",
    "    # Creative, Social, and Education\n",
    "    'Arts': 'Creative-Social-Education', 'Education': 'Creative-Social-Education',\n",
    "    'Religion': 'Creative-Social-Education', 'Communications-Media': 'Creative-Social-Education',\n",
    "    'Publishing': 'Creative-Social-Education', 'Non-Profit': 'Creative-Social-Education',\n",
    "    'Museums-Libraries': 'Creative-Social-Education', 'Fashion': 'Creative-Social-Education',\n",
    "    'Sports-Recreation': 'Creative-Social-Education', 'Tourism': 'Creative-Social-Education',\n",
    "    \n",
    "    # Public Services and Miscellaneous\n",
    "    'Government': 'Public-Services-Misc', 'Military': 'Public-Services-Misc',\n",
    "    'LawEnforcement-Security': 'Public-Services-Misc', 'Construction': 'Public-Services-Misc',\n",
    "    'Agriculture': 'Public-Services-Misc', 'Automotive': 'Public-Services-Misc',\n",
    "    'Maritime': 'Public-Services-Misc', 'indUnk': 'Public-Services-Misc', 'Student': 'Public-Services-Misc'\n",
    "}\n",
    "\n",
    "# Apply the mapping\n",
    "df['occupation_grouped'] = df['topic'].map(occupation_mapping)\n",
    "\n",
    "# Check distribution\n",
    "print(df['occupation_grouped'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cb8c63-dfcd-496a-82f6-e522d4fdfad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_group\n",
      "Young Adults    321447\n",
      "Adolescents     235867\n",
      "Adults          123970\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define age groups\n",
    "bins = [0, 17, 29, float('inf')]  # Adjust the ranges as per chosen grouping\n",
    "labels = ['Adolescents', 'Young Adults', 'Adults']\n",
    "\n",
    "# Create a new categorical column\n",
    "df['age_group'] = pd.cut(df['age'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "# Check distribution\n",
    "print(df['age_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 681284 entries, 0 to 681283\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count   Dtype   \n",
      "---  ------              --------------   -----   \n",
      " 0   id                  681284 non-null  int64   \n",
      " 1   gender              681284 non-null  object  \n",
      " 2   age                 681284 non-null  int64   \n",
      " 3   topic               681284 non-null  object  \n",
      " 4   sign                681284 non-null  object  \n",
      " 5   date                681284 non-null  object  \n",
      " 6   text                681284 non-null  object  \n",
      " 7   clean_text          681284 non-null  object  \n",
      " 8   gender_encoded      681284 non-null  int32   \n",
      " 9   occupation_grouped  681284 non-null  object  \n",
      " 10  age_group           681284 non-null  category\n",
      "dtypes: category(1), int32(1), int64(2), object(7)\n",
      "memory usage: 50.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e545dc-9c56-430b-aab1-c8cf2c0b5671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the gender column\n",
    "label_encoder = LabelEncoder()\n",
    "df['gender_encoded'] = label_encoder.fit_transform(df['gender'])  # Male: 0, Female: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 681284 entries, 0 to 681283\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count   Dtype   \n",
      "---  ------              --------------   -----   \n",
      " 0   id                  681284 non-null  int64   \n",
      " 1   gender              681284 non-null  object  \n",
      " 2   age                 681284 non-null  int64   \n",
      " 3   topic               681284 non-null  object  \n",
      " 4   sign                681284 non-null  object  \n",
      " 5   date                681284 non-null  object  \n",
      " 6   text                681284 non-null  object  \n",
      " 7   clean_text          681284 non-null  object  \n",
      " 8   gender_encoded      681284 non-null  int32   \n",
      " 9   occupation_grouped  681284 non-null  object  \n",
      " 10  age_group           681284 non-null  category\n",
      "dtypes: category(1), int32(1), int64(2), object(7)\n",
      "memory usage: 50.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c742189-543b-4267-a7f2-260579edc9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the age_group column\n",
    "label_encoder = LabelEncoder()\n",
    "df['age_encoded'] = label_encoder.fit_transform(df['age_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_encoded\n",
       "2    321447\n",
       "0    235867\n",
       "1    123970\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age_encoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>occupation_grouped</th>\n",
       "      <th>age_group</th>\n",
       "      <th>age_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "      <td>Info has been found 100 pages and 45 MB of pdf...</td>\n",
       "      <td>1</td>\n",
       "      <td>Public-Services-Misc</td>\n",
       "      <td>Adolescents</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "      <td>These are the team members Drewes van der Laag...</td>\n",
       "      <td>1</td>\n",
       "      <td>Public-Services-Misc</td>\n",
       "      <td>Adolescents</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "      <td>In het kader van kernfusie op aarde MAAK JE EI...</td>\n",
       "      <td>1</td>\n",
       "      <td>Public-Services-Misc</td>\n",
       "      <td>Adolescents</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "      <td>testing testing</td>\n",
       "      <td>1</td>\n",
       "      <td>Public-Services-Misc</td>\n",
       "      <td>Adolescents</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "      <td>Thanks to Yahoos Toolbar I can now capture the...</td>\n",
       "      <td>1</td>\n",
       "      <td>Business-Finance-Law</td>\n",
       "      <td>Adults</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  \\\n",
       "0             Info has been found (+/- 100 pages,...   \n",
       "1             These are the team members:   Drewe...   \n",
       "2             In het kader van kernfusie op aarde...   \n",
       "3                   testing!!!  testing!!!             \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...   \n",
       "\n",
       "                                          clean_text  gender_encoded  \\\n",
       "0  Info has been found 100 pages and 45 MB of pdf...               1   \n",
       "1  These are the team members Drewes van der Laag...               1   \n",
       "2  In het kader van kernfusie op aarde MAAK JE EI...               1   \n",
       "3                                    testing testing               1   \n",
       "4  Thanks to Yahoos Toolbar I can now capture the...               1   \n",
       "\n",
       "     occupation_grouped    age_group  age_encoded  \n",
       "0  Public-Services-Misc  Adolescents            0  \n",
       "1  Public-Services-Misc  Adolescents            0  \n",
       "2  Public-Services-Misc  Adolescents            0  \n",
       "3  Public-Services-Misc  Adolescents            0  \n",
       "4  Business-Finance-Law       Adults            1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc88623-b28f-4952-999d-e3f15a046e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[['clean_text','gender_encoded','occupation_grouped']],  # Replace 'other_features' with your actual columns\n",
    "    df['age_encoded'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38192e1-8327-496f-9b45-5032d4ae70ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 545027\n",
      "Test set size: 136257\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c21e71-8ce0-4540-9f43-7703424d2600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               occupation_grouped  occupation_encoded\n",
      "278509  Creative-Social-Education            1.349294\n",
      "572041       Public-Services-Misc            0.919386\n",
      "146044       Public-Services-Misc            0.919386\n",
      "569591       Public-Services-Misc            0.919386\n",
      "580033                       STEM            1.543025\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Target Encoder\n",
    "encoder = TargetEncoder(cols=['occupation_grouped'])\n",
    "\n",
    "# Fit the encoder on the training data and transform\n",
    "X_train['occupation_encoded'] = encoder.fit_transform(X_train['occupation_grouped'], y_train)\n",
    "\n",
    "# Apply the same transformation to the test data\n",
    "X_test['occupation_encoded'] = encoder.transform(X_test['occupation_grouped'])\n",
    "\n",
    "# Check results\n",
    "print(X_train[['occupation_grouped', 'occupation_encoded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c3b09b-930d-4c1c-bab3-e5cf83fb6268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GloVe embeddings (200-dimensional)\n",
    "glove_path = \"../glove.6B/glove.6B.200d.txt\"  # Path to your GloVe embeddings file\n",
    "embedding_dim = 200\n",
    "\n",
    "# Create a dictionary mapping words to their GloVe embeddings\n",
    "def load_glove_embeddings(file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = vector\n",
    "    return embeddings_index\n",
    "\n",
    "glove_embeddings = load_glove_embeddings(glove_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9c82f3-aef5-4deb-ae95-91a592ad35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text into GloVe embeddings\n",
    "def text_to_embedding(text, model, embedding_dim=200):\n",
    "    words = text.split()  # Tokenize text\n",
    "    embeddings = [model[word] for word in words if word in model]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)  # Average word vectors\n",
    "    else:\n",
    "        return np.zeros(embedding_dim)  # Return zero vector for empty or unknown words\n",
    "\n",
    "# Combine GloVe embeddings with occupation_encoded\n",
    "def combine_features(row, model, embedding_dim=200):\n",
    "    # GloVe embedding for text\n",
    "    text_embedding = text_to_embedding(row['clean_text'], model, embedding_dim)\n",
    "    \n",
    "    # Target-encoded occupation\n",
    "    occupation_encoded = np.array([row['occupation_encoded']], dtype=np.float32)\n",
    "\n",
    "    gender_encoded = np.array([row['gender_encoded']], dtype=np.float32)\n",
    "    \n",
    "    # Combine both features\n",
    "    return np.concatenate([text_embedding, occupation_encoded, gender_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>occupation_grouped</th>\n",
       "      <th>occupation_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278509</th>\n",
       "      <td>As usual I am getting my daily dose of Blog I ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Creative-Social-Education</td>\n",
       "      <td>1.349294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572041</th>\n",
       "      <td>im not sure how we are gonna do this but heres...</td>\n",
       "      <td>0</td>\n",
       "      <td>Public-Services-Misc</td>\n",
       "      <td>0.919386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146044</th>\n",
       "      <td>Its over We are all at our homes It was a grea...</td>\n",
       "      <td>0</td>\n",
       "      <td>Public-Services-Misc</td>\n",
       "      <td>0.919386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569591</th>\n",
       "      <td>Okay this post better go through because Ive a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Public-Services-Misc</td>\n",
       "      <td>0.919386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580033</th>\n",
       "      <td>urlLink Stencil Download</td>\n",
       "      <td>1</td>\n",
       "      <td>STEM</td>\n",
       "      <td>1.543025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  gender_encoded  \\\n",
       "278509  As usual I am getting my daily dose of Blog I ...               1   \n",
       "572041  im not sure how we are gonna do this but heres...               0   \n",
       "146044  Its over We are all at our homes It was a grea...               0   \n",
       "569591  Okay this post better go through because Ive a...               0   \n",
       "580033                           urlLink Stencil Download               1   \n",
       "\n",
       "               occupation_grouped  occupation_encoded  \n",
       "278509  Creative-Social-Education            1.349294  \n",
       "572041       Public-Services-Misc            0.919386  \n",
       "146044       Public-Services-Misc            0.919386  \n",
       "569591       Public-Services-Misc            0.919386  \n",
       "580033                       STEM            1.543025  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a64a04-bb29-4cfd-8df5-7396602e2381",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=['occupation_grouped'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>occupation_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278509</th>\n",
       "      <td>As usual I am getting my daily dose of Blog I ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.349294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572041</th>\n",
       "      <td>im not sure how we are gonna do this but heres...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.919386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146044</th>\n",
       "      <td>Its over We are all at our homes It was a grea...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.919386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569591</th>\n",
       "      <td>Okay this post better go through because Ive a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.919386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580033</th>\n",
       "      <td>urlLink Stencil Download</td>\n",
       "      <td>1</td>\n",
       "      <td>1.543025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  gender_encoded  \\\n",
       "278509  As usual I am getting my daily dose of Blog I ...               1   \n",
       "572041  im not sure how we are gonna do this but heres...               0   \n",
       "146044  Its over We are all at our homes It was a grea...               0   \n",
       "569591  Okay this post better go through because Ive a...               0   \n",
       "580033                           urlLink Stencil Download               1   \n",
       "\n",
       "        occupation_encoded  \n",
       "278509            1.349294  \n",
       "572041            0.919386  \n",
       "146044            0.919386  \n",
       "569591            0.919386  \n",
       "580033            1.543025  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278509    1\n",
       "572041    2\n",
       "146044    2\n",
       "569591    0\n",
       "580033    1\n",
       "         ..\n",
       "259178    0\n",
       "365838    2\n",
       "131932    2\n",
       "671155    2\n",
       "121958    0\n",
       "Name: age_encoded, Length: 545027, dtype: int32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>occupation_grouped</th>\n",
       "      <th>occupation_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>240436</th>\n",
       "      <td>1 Corinthians 511 But now I have written to yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>Public-Services-Misc</td>\n",
       "      <td>0.919386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54139</th>\n",
       "      <td>Having moved to Jersey City nearly a month ago...</td>\n",
       "      <td>0</td>\n",
       "      <td>Creative-Social-Education</td>\n",
       "      <td>1.349294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637911</th>\n",
       "      <td>urlLink Hey Metro Need To Save Money Take a Hi...</td>\n",
       "      <td>0</td>\n",
       "      <td>Public-Services-Misc</td>\n",
       "      <td>0.919386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61178</th>\n",
       "      <td>The most hilarious movie I have seen this year...</td>\n",
       "      <td>0</td>\n",
       "      <td>Public-Services-Misc</td>\n",
       "      <td>0.919386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314089</th>\n",
       "      <td>Short of being attached to the bumper of a pic...</td>\n",
       "      <td>0</td>\n",
       "      <td>STEM</td>\n",
       "      <td>1.543025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41229</th>\n",
       "      <td>83 days till Disney World I cant wait Im stayi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Public-Services-Misc</td>\n",
       "      <td>0.919386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501612</th>\n",
       "      <td>I found a cool website to calculate your life ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Public-Services-Misc</td>\n",
       "      <td>0.919386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45410</th>\n",
       "      <td>Im a gifted rapper That is to say I can rap al...</td>\n",
       "      <td>1</td>\n",
       "      <td>Business-Finance-Law</td>\n",
       "      <td>1.576155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79129</th>\n",
       "      <td>Normal never felt so good The AP History exam ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Public-Services-Misc</td>\n",
       "      <td>0.919386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195364</th>\n",
       "      <td>OH MY GOD Best BIG DAY OUT EVER If you Perthia...</td>\n",
       "      <td>0</td>\n",
       "      <td>Creative-Social-Education</td>\n",
       "      <td>1.349294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136257 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  gender_encoded  \\\n",
       "240436  1 Corinthians 511 But now I have written to yo...               0   \n",
       "54139   Having moved to Jersey City nearly a month ago...               0   \n",
       "637911  urlLink Hey Metro Need To Save Money Take a Hi...               0   \n",
       "61178   The most hilarious movie I have seen this year...               0   \n",
       "314089  Short of being attached to the bumper of a pic...               0   \n",
       "...                                                   ...             ...   \n",
       "41229   83 days till Disney World I cant wait Im stayi...               1   \n",
       "501612  I found a cool website to calculate your life ...               0   \n",
       "45410   Im a gifted rapper That is to say I can rap al...               1   \n",
       "79129   Normal never felt so good The AP History exam ...               1   \n",
       "195364  OH MY GOD Best BIG DAY OUT EVER If you Perthia...               0   \n",
       "\n",
       "               occupation_grouped  occupation_encoded  \n",
       "240436       Public-Services-Misc            0.919386  \n",
       "54139   Creative-Social-Education            1.349294  \n",
       "637911       Public-Services-Misc            0.919386  \n",
       "61178        Public-Services-Misc            0.919386  \n",
       "314089                       STEM            1.543025  \n",
       "...                           ...                 ...  \n",
       "41229        Public-Services-Misc            0.919386  \n",
       "501612       Public-Services-Misc            0.919386  \n",
       "45410        Business-Finance-Law            1.576155  \n",
       "79129        Public-Services-Misc            0.919386  \n",
       "195364  Creative-Social-Education            1.349294  \n",
       "\n",
       "[136257 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc21b13-6caf-4896-b4da-819ebf19dca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop(columns=['occupation_grouped'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>occupation_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>240436</th>\n",
       "      <td>1 Corinthians 511 But now I have written to yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.919386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54139</th>\n",
       "      <td>Having moved to Jersey City nearly a month ago...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.349294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637911</th>\n",
       "      <td>urlLink Hey Metro Need To Save Money Take a Hi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.919386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61178</th>\n",
       "      <td>The most hilarious movie I have seen this year...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.919386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314089</th>\n",
       "      <td>Short of being attached to the bumper of a pic...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.543025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41229</th>\n",
       "      <td>83 days till Disney World I cant wait Im stayi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.919386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501612</th>\n",
       "      <td>I found a cool website to calculate your life ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.919386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45410</th>\n",
       "      <td>Im a gifted rapper That is to say I can rap al...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.576155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79129</th>\n",
       "      <td>Normal never felt so good The AP History exam ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.919386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195364</th>\n",
       "      <td>OH MY GOD Best BIG DAY OUT EVER If you Perthia...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.349294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136257 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  gender_encoded  \\\n",
       "240436  1 Corinthians 511 But now I have written to yo...               0   \n",
       "54139   Having moved to Jersey City nearly a month ago...               0   \n",
       "637911  urlLink Hey Metro Need To Save Money Take a Hi...               0   \n",
       "61178   The most hilarious movie I have seen this year...               0   \n",
       "314089  Short of being attached to the bumper of a pic...               0   \n",
       "...                                                   ...             ...   \n",
       "41229   83 days till Disney World I cant wait Im stayi...               1   \n",
       "501612  I found a cool website to calculate your life ...               0   \n",
       "45410   Im a gifted rapper That is to say I can rap al...               1   \n",
       "79129   Normal never felt so good The AP History exam ...               1   \n",
       "195364  OH MY GOD Best BIG DAY OUT EVER If you Perthia...               0   \n",
       "\n",
       "        occupation_encoded  \n",
       "240436            0.919386  \n",
       "54139             1.349294  \n",
       "637911            0.919386  \n",
       "61178             0.919386  \n",
       "314089            1.543025  \n",
       "...                    ...  \n",
       "41229             0.919386  \n",
       "501612            0.919386  \n",
       "45410             1.576155  \n",
       "79129             0.919386  \n",
       "195364            1.349294  \n",
       "\n",
       "[136257 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377dbe20-040f-490e-ac92-4f470d5de821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training embeddings shape: (545027, 202)\n",
      "Test embeddings shape: (136257, 202)\n"
     ]
    }
   ],
   "source": [
    "# Apply embedding and feature combination to training and test sets\n",
    "X_train_combined = np.array([combine_features(row, glove_embeddings, embedding_dim) for _, row in X_train.iterrows()])\n",
    "X_test_combined = np.array([combine_features(row, glove_embeddings, embedding_dim) for _, row in X_test.iterrows()])\n",
    "# Confirm embedding shapes\n",
    "print(f\"Training embeddings shape: {X_train_combined.shape}\")\n",
    "print(f\"Test embeddings shape: {X_test_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a29633-2023-42ad-bdac-e4ea1b6de66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5897\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64     47221\n",
      "           1       0.46      0.05      0.09     24592\n",
      "           2       0.57      0.75      0.65     64444\n",
      "\n",
      "    accuracy                           0.59    136257\n",
      "   macro avg       0.55      0.48      0.46    136257\n",
      "weighted avg       0.57      0.59      0.55    136257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Train Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000)  # Increase max_iter for convergence\n",
    "log_reg.fit(X_train_combined, y_train)\n",
    "\n",
    "# Step 2: Evaluate the model\n",
    "y_pred = log_reg.predict(X_test_combined)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22de74a5-ed73-41ff-8bca-ea5b0d2ca937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5121\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.74      0.65     47221\n",
      "           1       0.33      0.57      0.42     24592\n",
      "           2       0.64      0.32      0.43     64444\n",
      "\n",
      "    accuracy                           0.51    136257\n",
      "   macro avg       0.51      0.55      0.50    136257\n",
      "weighted avg       0.56      0.51      0.50    136257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Train Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight='balanced')  # Increase max_iter for convergence\n",
    "log_reg.fit(X_train_combined, y_train)\n",
    "\n",
    "# Step 2: Evaluate the model\n",
    "y_pred = log_reg.predict(X_test_combined)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ab0751-941b-4663-9822-b3501f67839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''NN'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912d988d-1235-4c41-afc3-ffcbce17e18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd27de60-aef4-4cb2-8de7-44279d6118a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_combined, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test_combined, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0c7b6c-7057-425a-acc5-fd7fbc9790d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class AgeGroupPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(AgeGroupPredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.fc5 = nn.Linear(32, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d676a9-9c9d-4626-8d78-95d7c5b7521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "input_dim = X_train_combined.shape[1]\n",
    "num_classes = len(y_train.unique())  # Number of classes\n",
    "model = AgeGroupPredictor(input_dim, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f58a1d-7315-49a5-9805-9dd999d60b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Binary Cross Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c999e62-c852-4bde-9432-efb9bb7345cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:41<00:00, 414.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.8757, Accuracy: 58.81%\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:41<00:00, 414.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 0.8534, Accuracy: 59.89%\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:39<00:00, 428.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 0.8456, Accuracy: 60.40%\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:40<00:00, 417.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 0.8404, Accuracy: 60.68%\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:40<00:00, 420.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.8358, Accuracy: 60.95%\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:40<00:00, 424.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 0.8321, Accuracy: 61.14%\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:41<00:00, 410.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 0.8295, Accuracy: 61.29%\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:44<00:00, 386.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 0.8261, Accuracy: 61.44%\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:39<00:00, 428.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 0.8242, Accuracy: 61.50%\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:38<00:00, 438.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 0.8223, Accuracy: 61.59%\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:38<00:00, 443.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 0.8200, Accuracy: 61.75%\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:40<00:00, 425.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 0.8186, Accuracy: 61.85%\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:40<00:00, 420.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 0.8177, Accuracy: 61.90%\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:40<00:00, 421.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 0.8159, Accuracy: 61.93%\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:40<00:00, 419.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 0.8140, Accuracy: 62.05%\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:40<00:00, 421.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.8134, Accuracy: 62.14%\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:38<00:00, 438.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 0.8121, Accuracy: 62.15%\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:38<00:00, 444.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 0.8110, Accuracy: 62.25%\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:38<00:00, 445.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 0.8105, Accuracy: 62.25%\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 451.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.8099, Accuracy: 62.29%\n",
      "Test Accuracy: 0.6259\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.69      0.68     47221\n",
      "           1       0.68      0.09      0.17     24592\n",
      "           2       0.60      0.78      0.68     64444\n",
      "\n",
      "    accuracy                           0.63    136257\n",
      "   macro avg       0.65      0.52      0.51    136257\n",
      "weighted avg       0.64      0.63      0.59    136257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    correct=0\n",
    "    total = 0\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for i in tqdm(range(0, len(X_train_tensor), batch_size), desc=\"Training Batches\"):\n",
    "        # Batch data\n",
    "        batch_X = X_train_tensor[i:i+batch_size]\n",
    "        batch_y = y_train_tensor[i:i+batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "        total += batch_y.size(0)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_loss = epoch_loss / (len(X_train_tensor) // batch_size)\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    y_pred = torch.argmax(outputs, dim=1)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test_tensor.cpu(), y_pred.cpu()):.4f}\")\n",
    "print(\"\\nClassification Report:\")    \n",
    "print(classification_report(y_test_tensor.cpu(), y_pred.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a670a-84d5-492c-99ad-ec5ca58fee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9208ce36-977b-4626-bf33-72ac3924786f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''using Contextual embeddings'''\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6036922e-3fb8-4211-8311-a81522a4fcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(texts, tokenizer, model, max_length=128):\n",
    "    embeddings = []\n",
    "    for text in tqdm(texts, desc=\"Generating Embeddings\"):\n",
    "        # Tokenize text\n",
    "        tokens = tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        # print(tokens)\n",
    "        input_ids = tokens['input_ids'].to(device)\n",
    "        # print(input_ids)\n",
    "        attention_mask = tokens['attention_mask'].to(device)\n",
    "        # print(attention_mask)\n",
    "\n",
    "        # Pass through model\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            # print(outputs)\n",
    "            token_embeddings = outputs.last_hidden_state  # Shape: [batch_size, sequence_length, hidden_size]\n",
    "            sentence_embedding = torch.mean(token_embeddings, dim=1)  # Mean pooling over tokens\n",
    "            # print(sentence_embedding)\n",
    "            embeddings.append(sentence_embedding.cpu())\n",
    "    \n",
    "    return torch.cat(embeddings, dim=0)  # Return as a single tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55112a37-618a-49c3-b956-b6948ccaa394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''using Contextual embeddings'''\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca27a267-219e-46d6-9454-6bb58b0c3e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(texts, tokenizer, model, max_length=128, batch_size=32):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Generating Embeddings\"):\n",
    "        # Tokenize text\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        tokens = tokenizer(\n",
    "            batch_texts,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        # print(tokens)\n",
    "        input_ids = tokens['input_ids'].to(device)\n",
    "        # print(input_ids)\n",
    "        attention_mask = tokens['attention_mask'].to(device)\n",
    "        # print(attention_mask)\n",
    "\n",
    "        # Pass through model\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            # print(outputs)\n",
    "            token_embeddings = outputs.last_hidden_state  # Shape: [batch_size, sequence_length, hidden_size]\n",
    "            sentence_embedding = torch.mean(token_embeddings, dim=1)  # Mean pooling over tokens\n",
    "            # print(sentence_embedding)\n",
    "            embeddings.append(sentence_embedding)\n",
    "    \n",
    "    return torch.cat(embeddings, dim=0)  # Return as a single tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e09fca3-c96b-4092-ba8b-f74b93360123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 17033/17033 [31:17<00:00,  9.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for training and testing datasets\n",
    "X_train_embeddings = generate_embeddings(X_train['clean_text'].tolist(), tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1967570d-d9bf-4393-a501-5e9f5f9b1d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Train Features Shape: torch.Size([545027, 770])\n"
     ]
    }
   ],
   "source": [
    "occupation_train_tensor = torch.tensor(X_train['occupation_encoded'].values, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "gender_train_tensor = torch.tensor(X_train['gender_encoded'].values, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "X_train_combined = torch.cat([X_train_embeddings, occupation_train_tensor, gender_train_tensor], dim=1)\n",
    "\n",
    "print(f\"Combined Train Features Shape: {X_train_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b318deb3-c360-414f-b8fb-89736685794c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 4259/4259 [08:15<00:00,  8.59it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_embeddings = generate_embeddings(X_test['clean_text'].tolist(), tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2656a3b-4d45-46d9-8e87-dae867b2154d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Test Features Shape: torch.Size([136257, 770])\n"
     ]
    }
   ],
   "source": [
    "occupation_test_tensor = torch.tensor(X_test['occupation_encoded'].values, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "gender_test_tensor = torch.tensor(X_test['gender_encoded'].values, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "X_test_combined = torch.cat([X_test_embeddings, occupation_test_tensor, gender_test_tensor], dim=1)\n",
    "\n",
    "print(f\"Combined Test Features Shape: {X_test_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b4fcec-b4ad-4ac3-bd7b-81482f6b04fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-69-c0daa6752426>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(X_train_combined, dtype=torch.float32).to(device)\n",
      "<ipython-input-69-c0daa6752426>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test_combined, dtype=torch.float32).to(device)\n"
     ]
    }
   ],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_combined, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test_combined, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bef5d2-a603-44e8-a54f-2f55fa3b7c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class AgeGroupPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(AgeGroupPredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.fc5 = nn.Linear(32, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4c9a3d-6fed-466b-be18-97c1b30ee6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "input_dim = X_train_combined.shape[1]\n",
    "num_classes = len(y_train.unique())  # Number of classes\n",
    "model = AgeGroupPredictor(input_dim, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51663a7e-aaeb-4be8-8a69-374b927ad49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Binary Cross Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9fa7c2-f4d0-4ea8-b335-65e233601902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:40<00:00, 422.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.8208, Accuracy: 61.87%\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 454.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 0.7939, Accuracy: 63.37%\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 451.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 0.7851, Accuracy: 63.81%\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 462.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 0.7790, Accuracy: 64.15%\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 456.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.7741, Accuracy: 64.38%\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 466.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 0.7702, Accuracy: 64.69%\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 460.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 0.7668, Accuracy: 64.88%\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 453.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 0.7642, Accuracy: 64.94%\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 455.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 0.7615, Accuracy: 65.15%\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 456.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 0.7585, Accuracy: 65.39%\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 455.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 0.7567, Accuracy: 65.44%\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 454.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 0.7540, Accuracy: 65.54%\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 459.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 0.7531, Accuracy: 65.58%\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 451.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 0.7515, Accuracy: 65.72%\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 454.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 0.7490, Accuracy: 65.88%\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 459.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.7477, Accuracy: 65.91%\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 454.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 0.7465, Accuracy: 65.96%\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 449.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 0.7454, Accuracy: 66.04%\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 454.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 0.7437, Accuracy: 66.13%\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 452.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.7428, Accuracy: 66.14%\n",
      "Test Accuracy: 0.6590\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.73      0.72     47221\n",
      "           1       0.73      0.14      0.24     24592\n",
      "           2       0.62      0.80      0.70     64444\n",
      "\n",
      "    accuracy                           0.66    136257\n",
      "   macro avg       0.69      0.56      0.55    136257\n",
      "weighted avg       0.67      0.66      0.63    136257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    correct=0\n",
    "    total = 0\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for i in tqdm(range(0, len(X_train_tensor), batch_size), desc=\"Training Batches\"):\n",
    "        # Batch data\n",
    "        batch_X = X_train_tensor[i:i+batch_size]\n",
    "        batch_y = y_train_tensor[i:i+batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "        total += batch_y.size(0)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_loss = epoch_loss / (len(X_train_tensor) // batch_size)\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    y_pred = torch.argmax(outputs, dim=1)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test_tensor.cpu(), y_pred.cpu()):.4f}\")\n",
    "print(\"\\nClassification Report:\")    \n",
    "print(classification_report(y_test_tensor.cpu(), y_pred.cpu()))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
