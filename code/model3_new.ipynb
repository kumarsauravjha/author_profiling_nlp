{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ea8c4d-38f9-4102-ac95-6db59257c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\91914\\.cache\\kagglehub\\datasets\\rtatman\\blog-authorship-corpus\\versions\\2\n",
      "Loaded dataset from C:\\Users\\91914\\.cache\\kagglehub\\datasets\\rtatman\\blog-authorship-corpus\\versions\\2\\blogtext.csv\n",
      "        id gender  age              topic      sign          date  \\\n",
      "0  2059027   male   15            Student       Leo   14,May,2004   \n",
      "1  2059027   male   15            Student       Leo   13,May,2004   \n",
      "2  2059027   male   15            Student       Leo   12,May,2004   \n",
      "3  2059027   male   15            Student       Leo   12,May,2004   \n",
      "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
      "\n",
      "                                                text  \n",
      "0             Info has been found (+/- 100 pages,...  \n",
      "1             These are the team members:   Drewe...  \n",
      "2             In het kader van kernfusie op aarde...  \n",
      "3                   testing!!!  testing!!!            \n",
      "4               Thanks to Yahoo!'s Toolbar I can ...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Download the dataset\n",
    "path = kagglehub.dataset_download(\"rtatman/blog-authorship-corpus\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Optional: If the dataset includes a CSV file, load it into pandas\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming there's a CSV file in the downloaded path\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        csv_path = os.path.join(path, file)\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(f\"Loaded dataset from {csv_path}\")\n",
    "        break\n",
    "\n",
    "# Example usage of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If for some reason the above code doesn't work, simply go to \"https://www.kaggle.com/datasets/rtatman/blog-authorship-corpus\", download the dataset and load using the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d8876e-0813-4258-a178-bacfd8829dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# df = pd.read_csv(\"archive/blogtext.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e26e83b-3e61-41f2-9126-4f8da3677ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "17    80859\n",
       "24    80071\n",
       "23    72889\n",
       "16    72708\n",
       "25    67051\n",
       "26    55312\n",
       "27    46124\n",
       "15    41767\n",
       "14    27400\n",
       "34    21347\n",
       "33    17584\n",
       "35    17462\n",
       "36    14229\n",
       "13    13133\n",
       "37     9317\n",
       "38     7545\n",
       "39     5556\n",
       "40     5016\n",
       "45     4482\n",
       "43     4230\n",
       "41     3738\n",
       "48     3572\n",
       "42     2908\n",
       "46     2733\n",
       "47     2207\n",
       "44     2044\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "df['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d6e6c9-e32d-472f-a966-0c7a8145ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# Clean the text data\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove non-alphanumeric characters and extra spaces\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ffc6a-125b-4241-8f0f-2781dd38e6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "# Encode the gender column\n",
    "label_encoder = LabelEncoder()\n",
    "df['gender_encoded'] = label_encoder.fit_transform(df['gender'])  # Male: 0, Female: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e5cac5-e485-4886-9d38-f3778c0040a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occupation_grouped\n",
      "Public-Services-Misc         420683\n",
      "Creative-Social-Education    122837\n",
      "STEM                          91538\n",
      "Business-Finance-Law          46226\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Define the mapping\n",
    "occupation_mapping = {\n",
    "    # STEM\n",
    "    'Technology': 'STEM', 'Engineering': 'STEM', 'Internet': 'STEM', 'Science': 'STEM',\n",
    "    'Biotech': 'STEM', 'Telecommunications': 'STEM', 'Manufacturing': 'STEM', \n",
    "    'Chemicals': 'STEM', 'Architecture': 'STEM', 'Environment': 'STEM', 'Maritime': 'STEM',\n",
    "    \n",
    "    # Business, Finance, and Law\n",
    "    'BusinessServices': 'Business-Finance-Law', 'Banking': 'Business-Finance-Law',\n",
    "    'Accounting': 'Business-Finance-Law', 'InvestmentBanking': 'Business-Finance-Law',\n",
    "    'RealEstate': 'Business-Finance-Law', 'Marketing': 'Business-Finance-Law', \n",
    "    'Advertising': 'Business-Finance-Law', 'Consulting': 'Business-Finance-Law',\n",
    "    'Law': 'Business-Finance-Law', 'HumanResources': 'Business-Finance-Law',\n",
    "    'Transportation': 'Business-Finance-Law',\n",
    "    \n",
    "    # Creative, Social, and Education\n",
    "    'Arts': 'Creative-Social-Education', 'Education': 'Creative-Social-Education',\n",
    "    'Religion': 'Creative-Social-Education', 'Communications-Media': 'Creative-Social-Education',\n",
    "    'Publishing': 'Creative-Social-Education', 'Non-Profit': 'Creative-Social-Education',\n",
    "    'Museums-Libraries': 'Creative-Social-Education', 'Fashion': 'Creative-Social-Education',\n",
    "    'Sports-Recreation': 'Creative-Social-Education', 'Tourism': 'Creative-Social-Education',\n",
    "    \n",
    "    # Public Services and Miscellaneous\n",
    "    'Government': 'Public-Services-Misc', 'Military': 'Public-Services-Misc',\n",
    "    'LawEnforcement-Security': 'Public-Services-Misc', 'Construction': 'Public-Services-Misc',\n",
    "    'Agriculture': 'Public-Services-Misc', 'Automotive': 'Public-Services-Misc',\n",
    "    'Maritime': 'Public-Services-Misc', 'indUnk': 'Public-Services-Misc', 'Student': 'Public-Services-Misc'\n",
    "}\n",
    "\n",
    "# Apply the mapping\n",
    "df['occupation_grouped'] = df['topic'].map(occupation_mapping)\n",
    "\n",
    "# Check distribution\n",
    "print(df['occupation_grouped'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35ebfc4-382f-4b17-a53f-ae4e82adf324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_group\n",
      "Young Adults    321447\n",
      "Adolescents     235867\n",
      "Adults          123970\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Define age groups\n",
    "bins = [0, 17, 29, float('inf')]  # Adjust the ranges as per chosen grouping\n",
    "labels = ['Adolescents', 'Young Adults', 'Adults']\n",
    "\n",
    "# Create a new categorical column\n",
    "df['age_group'] = pd.cut(df['age'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "# Check distribution\n",
    "print(df['age_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b322d0df-b10a-41ea-90fc-99b50cfe0304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Encode the gender column\n",
    "label_encoder = LabelEncoder()\n",
    "df['gender_encoded'] = label_encoder.fit_transform(df['gender'])  # Male: 0, Female: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eea9732-eb44-4c2e-87b0-cff2b7269b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Encode the age_group column\n",
    "label_encoder = LabelEncoder()\n",
    "df['age_encoded'] = label_encoder.fit_transform(df['age_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1197edda-82e5-454a-bf03-034b9c81e9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Split your data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[['clean_text','gender_encoded','occupation_grouped']],  # Replace 'other_features' with your actual columns\n",
    "    df['age_encoded'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0be64a6-58b4-41b3-af4b-01dbdeb93a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 545027\n",
      "Test set size: 136257\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d513a9-e101-43e8-99a2-84e18e98c564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               occupation_grouped  occupation_encoded\n",
      "278509  Creative-Social-Education            1.349294\n",
      "572041       Public-Services-Misc            0.919386\n",
      "146044       Public-Services-Misc            0.919386\n",
      "569591       Public-Services-Misc            0.919386\n",
      "580033                       STEM            1.543025\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Initialize the Target Encoder\n",
    "encoder = TargetEncoder(cols=['occupation_grouped'])\n",
    "\n",
    "# Fit the encoder on the training data and transform\n",
    "X_train['occupation_encoded'] = encoder.fit_transform(X_train['occupation_grouped'], y_train)\n",
    "\n",
    "# Apply the same transformation to the test data\n",
    "X_test['occupation_encoded'] = encoder.transform(X_test['occupation_grouped'])\n",
    "\n",
    "# Check results\n",
    "print(X_train[['occupation_grouped', 'occupation_encoded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f00507-fb75-48e5-aa77-b78193288488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "X_train.drop(columns=['occupation_grouped'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df44445b-84d5-427f-bf6a-22f4e1082968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "X_test.drop(columns=['occupation_grouped'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90541cd9-7fe4-4b96-9924-782eebcdb789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269fbb4e-2f2d-408b-bc98-a2154927ae17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "'''using Contextual embeddings'''\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f93df69-3241-4d1c-8f81-62c6d6c29362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a6581b-6a71-439a-a727-6e654a588a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "def generate_embeddings(texts, tokenizer, model, max_length=128, batch_size=32):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Generating Embeddings\"):\n",
    "        # Tokenize text\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        tokens = tokenizer(\n",
    "            batch_texts,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        # print(tokens)\n",
    "        input_ids = tokens['input_ids'].to(device)\n",
    "        # print(input_ids)\n",
    "        attention_mask = tokens['attention_mask'].to(device)\n",
    "        # print(attention_mask)\n",
    "\n",
    "        # Pass through model\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            # print(outputs)\n",
    "            token_embeddings = outputs.last_hidden_state  # Shape: [batch_size, sequence_length, hidden_size]\n",
    "            sentence_embedding = torch.mean(token_embeddings, dim=1)  # Mean pooling over tokens\n",
    "            # print(sentence_embedding)\n",
    "            embeddings.append(sentence_embedding)\n",
    "    \n",
    "    return torch.cat(embeddings, dim=0)  # Return as a single tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229d1a6e-718b-437d-ac81-73926212c1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 17033/17033 [28:43<00:00,  9.88it/s]\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "# Generate embeddings for training and testing datasets\n",
    "X_train_embeddings = generate_embeddings(X_train['clean_text'].tolist(), tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846636b0-3ebc-40d7-9785-3d126f6c004a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Train Features Shape: torch.Size([545027, 770])\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "occupation_train_tensor = torch.tensor(X_train['occupation_encoded'].values, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "gender_train_tensor = torch.tensor(X_train['gender_encoded'].values, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "X_train_combined = torch.cat([X_train_embeddings, occupation_train_tensor, gender_train_tensor], dim=1)\n",
    "\n",
    "print(f\"Combined Train Features Shape: {X_train_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740f53fb-8eda-437d-87ff-20ad173bd8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 4259/4259 [07:08<00:00,  9.95it/s]\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "X_test_embeddings = generate_embeddings(X_test['clean_text'].tolist(), tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72cf475-be25-4ed0-9093-5305efbf6e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Test Features Shape: torch.Size([136257, 770])\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "occupation_test_tensor = torch.tensor(X_test['occupation_encoded'].values, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "gender_test_tensor = torch.tensor(X_test['gender_encoded'].values, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "X_test_combined = torch.cat([X_test_embeddings, occupation_test_tensor, gender_test_tensor], dim=1)\n",
    "\n",
    "print(f\"Combined Test Features Shape: {X_test_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6d3114-86ab-4f36-8dca-4a45b9569c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-c0daa6752426>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_tensor = torch.tensor(X_train_combined, dtype=torch.float32).to(device)\n",
      "<ipython-input-27-c0daa6752426>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensor = torch.tensor(X_test_combined, dtype=torch.float32).to(device)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_combined, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test_combined, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a99429-eaec-4aba-9e86-7363e375c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Define the model\n",
    "class AgeGroupPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(AgeGroupPredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.fc5 = nn.Linear(32, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab98df7-b399-4500-8684-6106de3d8577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Initialize model\n",
    "input_dim = X_train_combined.shape[1]\n",
    "num_classes = len(y_train.unique())  # Number of classes\n",
    "model = AgeGroupPredictor(input_dim, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c60f35-250f-4670-813f-be2b69a17a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Binary Cross Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62f771a-fb76-4c7c-82fd-42e77e6cb78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 452.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.8209, Accuracy: 61.95%\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:35<00:00, 477.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Loss: 0.7944, Accuracy: 63.32%\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:35<00:00, 476.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Loss: 0.7857, Accuracy: 63.81%\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:35<00:00, 475.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Loss: 0.7789, Accuracy: 64.20%\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:35<00:00, 474.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Loss: 0.7745, Accuracy: 64.47%\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:35<00:00, 475.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Loss: 0.7699, Accuracy: 64.77%\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:35<00:00, 476.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Loss: 0.7668, Accuracy: 64.90%\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 471.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Loss: 0.7637, Accuracy: 65.05%\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:35<00:00, 475.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Loss: 0.7617, Accuracy: 65.15%\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 468.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 0.7596, Accuracy: 65.32%\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 459.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Loss: 0.7571, Accuracy: 65.40%\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 462.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Loss: 0.7552, Accuracy: 65.55%\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 458.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Loss: 0.7532, Accuracy: 65.54%\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 460.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Loss: 0.7514, Accuracy: 65.76%\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 461.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Loss: 0.7498, Accuracy: 65.76%\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 461.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Loss: 0.7483, Accuracy: 65.92%\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 458.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Loss: 0.7468, Accuracy: 65.94%\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 463.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Loss: 0.7457, Accuracy: 66.05%\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 462.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Loss: 0.7435, Accuracy: 66.17%\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:37<00:00, 460.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Loss: 0.7425, Accuracy: 66.25%\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 466.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Loss: 0.7418, Accuracy: 66.30%\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 466.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Loss: 0.7406, Accuracy: 66.34%\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 462.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Loss: 0.7396, Accuracy: 66.38%\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 465.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Loss: 0.7379, Accuracy: 66.45%\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 471.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Loss: 0.7369, Accuracy: 66.55%\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 469.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Loss: 0.7364, Accuracy: 66.54%\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 472.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Loss: 0.7352, Accuracy: 66.57%\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 472.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Loss: 0.7341, Accuracy: 66.66%\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 469.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Loss: 0.7332, Accuracy: 66.73%\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 473.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Loss: 0.7330, Accuracy: 66.72%\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 464.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Loss: 0.7322, Accuracy: 66.78%\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 464.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Loss: 0.7306, Accuracy: 66.85%\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 465.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Loss: 0.7302, Accuracy: 66.85%\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 465.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Loss: 0.7298, Accuracy: 66.88%\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 464.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Loss: 0.7289, Accuracy: 66.95%\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 462.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Loss: 0.7282, Accuracy: 66.98%\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 463.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Loss: 0.7277, Accuracy: 67.07%\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 464.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Loss: 0.7271, Accuracy: 67.13%\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 462.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Loss: 0.7262, Accuracy: 67.10%\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 465.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Loss: 0.7252, Accuracy: 67.14%\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 471.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Loss: 0.7248, Accuracy: 67.18%\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 470.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Loss: 0.7250, Accuracy: 67.17%\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 465.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Loss: 0.7240, Accuracy: 67.27%\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 468.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Loss: 0.7236, Accuracy: 67.23%\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 467.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Loss: 0.7230, Accuracy: 67.27%\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 467.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Loss: 0.7226, Accuracy: 67.32%\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 470.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Loss: 0.7218, Accuracy: 67.34%\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 468.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Loss: 0.7210, Accuracy: 67.45%\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 465.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Loss: 0.7212, Accuracy: 67.37%\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 17033/17033 [00:36<00:00, 471.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Loss: 0.7205, Accuracy: 67.42%\n",
      "Test Accuracy: 0.6673\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73     47221\n",
      "           1       0.68      0.19      0.30     24592\n",
      "           2       0.63      0.80      0.71     64444\n",
      "\n",
      "    accuracy                           0.67    136257\n",
      "   macro avg       0.68      0.58      0.58    136257\n",
      "weighted avg       0.67      0.67      0.64    136257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Training loop\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    correct=0\n",
    "    total = 0\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for i in tqdm(range(0, len(X_train_tensor), batch_size), desc=\"Training Batches\"):\n",
    "        # Batch data\n",
    "        batch_X = X_train_tensor[i:i+batch_size]\n",
    "        batch_y = y_train_tensor[i:i+batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "        total += batch_y.size(0)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_loss = epoch_loss / (len(X_train_tensor) // batch_size)\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    y_pred = torch.argmax(outputs, dim=1)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test_tensor.cpu(), y_pred.cpu()):.4f}\")\n",
    "print(\"\\nClassification Report:\")    \n",
    "print(classification_report(y_test_tensor.cpu(), y_pred.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1233,  0.2310,  0.0882,  ..., -0.1283,  1.3493,  1.0000],\n",
       "        [ 0.0530,  0.0098,  0.1782,  ...,  0.0212,  0.9194,  0.0000],\n",
       "        [ 0.1453,  0.0833,  0.4302,  ..., -0.1145,  0.9194,  0.0000],\n",
       "        ...,\n",
       "        [ 0.0402, -0.0676,  0.2227,  ..., -0.0413,  0.9194,  0.0000],\n",
       "        [-0.0404,  0.1895,  0.2807,  ...,  0.0770,  1.3493,  0.0000],\n",
       "        [-0.1729,  0.1082,  0.3781,  ..., -0.0182,  1.3493,  1.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([545027, 770])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6351d5f2-860d-479b-953f-78e48701fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "torch.save(X_train_embeddings, \"X_train_embeddings.pt\")\n",
    "torch.save(X_test_embeddings, \"X_train_embeddings.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63be4e7e-f111-419d-8b35-7509f53d2bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "torch.save(X_train_embeddings, \"X_train_embeddings.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20c2eaf-33e0-405c-b7ab-9d658b9722b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "torch.save(X_test_embeddings, \"X_test_embeddings.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
